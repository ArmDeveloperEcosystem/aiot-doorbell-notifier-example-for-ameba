{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AIoT doorbell notifier example for Ameba\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ArmDeveloperEcosystem/aiot-doorbell-notifier-example-for-ameba/blob/main/model_training.ipynb)\n",
        "\n",
        "```python\n",
        "# SPDX-FileCopyrightText: Copyright 2023 Arm Limited and/or its affiliates <open-source-office@arm.com>\n",
        "# SPDX-License-Identifier: MIT\n",
        "```\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This notebook trains an Audio Classification model to detect a doorbell sound.\n",
        "\n",
        "A [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) based pipeline is created to transform audio data from public datasets into Mel power spectrogram images. A model with the `\"tiny_conv\"` architecture  is then used as the ML classifier.\n",
        "\n",
        "The ML classifier is created in two phases, first a baseline model is trained on the entire [ESC-50 dataset](https://github.com/karolpiczak/ESC-50), then a model that re-uses the CNN layer of the baseline model is trained in a subset of the [FSD50K dataset](https://zenodo.org/record/4060432) with the following classes:\n",
        "\n",
        " * Doorbell -üö™üîî\n",
        " * Music - üé∂\n",
        " * Domestic and home sounds - üè†\n",
        " * Human voice - üó£\n",
        " * Hands (clapping, finger snapping) üëè ü´∞\n",
        "\n",
        "**Note:** *The trained model has relative poor metrics, but is still able to detect a doorbell sound in our testing. Further data cleaning and hyperparameter tuning needs to be done to get a model with better metrics.* \n"
      ],
      "metadata": {
        "id": "v30Ubys6qGn7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies\n",
        "\n",
        "TensorFlow 2.11.* is compatible with `tensorflow_io` 0.28.* - as per the [\"TensorFlow Version Compatibility\" section of the TensorFlow I/O Read Me]( https://github.com/tensorflow/io#tensorflow-version-compatibility)."
      ],
      "metadata": {
        "id": "xKXxLSRXvDOF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdRW2dp5srql"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade \"matplotlib==3.6.*\" \"pandas==1.5.*\" \"tensorflow==2.11.*\" \"tensorflow_io==0.28.*\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import modules"
      ],
      "metadata": {
        "id": "QqNz-3CbwGjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import IPython\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio"
      ],
      "metadata": {
        "id": "U2X7WbwLs3Is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ESC-50 dataset and model\n",
        "\n",
        "Download and extract the ESC-50 data and place it in the `datasets/ESC-50` directory:"
      ],
      "metadata": {
        "id": "chjHmWlMx9Ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_ = tf.keras.utils.get_file(\n",
        "    \"ESC-50.zip\",\n",
        "    \"https://github.com/karoldvl/ESC-50/archive/master.zip\",\n",
        "    cache_subdir=\"datasets\",\n",
        "    extract=True,\n",
        "    cache_dir=\"./\",\n",
        ")\n",
        "\n",
        "os.rename(\n",
        "    os.path.join(\"datasets\", \"ESC-50-master\"),\n",
        "    os.path.join(\"datasets\", \"ESC-50\")\n",
        ")"
      ],
      "metadata": {
        "id": "SRA3Fo-8tPCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the ESC-50 metadata CSV file using Pandas:"
      ],
      "metadata": {
        "id": "nIbiTVoZyThT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "esc50_csv_path = os.path.join('datasets', 'ESC-50', \"meta\", \"esc50.csv\")\n",
        "\n",
        "esc50_df = pd.read_csv(esc50_csv_path)\n",
        "\n",
        "esc50_df.head(-1)"
      ],
      "metadata": {
        "id": "ERe8bYDzuCXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add a new column with the filepath based the `filename` and path of the ESC-50 dataset audio folder.\n"
      ],
      "metadata": {
        "id": "vsA3iSiyyZ6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "esc50_audio_path = os.path.join(\"datasets\", \"ESC-50\", \"audio\")\n",
        "\n",
        "esc50_filepaths = esc50_df['filename'].apply(lambda filename: os.path.join(esc50_audio_path, filename))\n",
        "\n",
        "esc50_df = esc50_df.assign(filepath=esc50_filepaths)\n",
        "\n",
        "esc50_df.head(-1)"
      ],
      "metadata": {
        "id": "7-Ctko4ttz7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the `fold` column value to determine training (80%), validation (10%) and testing (10%) splits.\n"
      ],
      "metadata": {
        "id": "kMAKLXbcyljE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def esc_50_fold_to_split(fold):\n",
        "  if fold < 4:\n",
        "    return \"train\"\n",
        "  elif fold == 4:\n",
        "    return \"val\"\n",
        "  else:\n",
        "    return \"test\"\n",
        "\n",
        "esc50_splits = esc50_df[\"fold\"].apply(esc_50_fold_to_split)\n",
        "\n",
        "esc50_df = esc50_df.assign(split=esc50_splits)\n",
        "\n",
        "esc50_df.head(-1)"
      ],
      "metadata": {
        "id": "ABO80Y3cxCCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a `tf.data.Dataset` from the dataframe:"
      ],
      "metadata": {
        "id": "wh_yrkyTy4Pi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "esc50_ds = tf.data.Dataset.from_tensor_slices((\n",
        "    esc50_df.filepath,\n",
        "    esc50_df.target,\n",
        "    esc50_df.split\n",
        "))"
      ],
      "metadata": {
        "id": "p7KYcBxJ5m-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function to load the wave file data"
      ],
      "metadata": {
        "id": "Vubnlv1TzBcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_wav(filename, channels=1, sample_rate=16000):\n",
        "  # read the contents of the wave file\n",
        "  contents = tf.io.read_file(filename)\n",
        "\n",
        "  # decode the wave file\n",
        "  audio, audio_sample_rate = tf.audio.decode_wav(contents, desired_channels=channels)\n",
        "\n",
        "  # resample the audio to the desired sample rate\n",
        "  resampled_audio = tfio.audio.resample(\n",
        "      tf.squeeze(audio, axis=-1),\n",
        "      rate_in=tf.cast(audio_sample_rate, dtype=tf.int64),\n",
        "      rate_out=sample_rate\n",
        "  )\n",
        "\n",
        "  return resampled_audio"
      ],
      "metadata": {
        "id": "ZIYZbOXks-ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the audio data for each `filepath` in the dataset:"
      ],
      "metadata": {
        "id": "_F_4zYbGzH0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "esc50_ds = esc50_ds.map(lambda filepath, label, split: (load_wav(filepath), label, split))"
      ],
      "metadata": {
        "id": "BrAKzTDx-KxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function to trim silence from the start and end of audio data using [`tfio.audio.trim`](https://www.tensorflow.org/io/api_docs/python/tfio/audio/trim) and then apply it on the dataset."
      ],
      "metadata": {
        "id": "DalOSqr8zTJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trim(samples, label, split):\n",
        "  position = tfio.audio.trim(samples, axis=0, epsilon=0.1)\n",
        "\n",
        "  start = tf.math.maximum(position[0] - 320, 0)\n",
        "  stop = tf.math.minimum(\n",
        "      position[1] + 320,\n",
        "      tf.cast(tf.shape(samples)[0], tf.int64)\n",
        "  )\n",
        "\n",
        "  trimmed = samples[start:stop]\n",
        "\n",
        "  return trimmed, label, split\n",
        "\n",
        "esc50_ds = esc50_ds.map(trim)"
      ],
      "metadata": {
        "id": "ANXWVFMsIjch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function to frame audio data into 16000 samples with a stride of 1600 samples using [`tf.signal.frame`](https://www.tensorflow.org/api_docs/python/tf/signal/frame) and then apply it on the dataset."
      ],
      "metadata": {
        "id": "-uCQY6Ymz0PT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def frame(samples, label, split):\n",
        "  frames = tf.signal.frame(samples, 16000, 1600)\n",
        "\n",
        "  num_frames = tf.shape(frames)[0]\n",
        "\n",
        "  return frames, tf.repeat(label, num_frames), tf.repeat(split, num_frames)\n",
        "\n",
        "esc50_ds = esc50_ds.map(frame).unbatch()"
      ],
      "metadata": {
        "id": "YOIZyswFJIE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a functions to:\n",
        " * Convert each frame into a spectrogram using samples using [`tf.signal.stft`](https://www.tensorflow.org/api_docs/python/tf/signal/stft)\n",
        " * Convert each spectrogram to Mel scale using [`tfio.audio.melscale`](https://www.tensorflow.org/io/api_docs/python/tfio/audio/melscale)\n",
        " * Convert each Mel spectrogram to dB [`tfio.audio.dbscale`](https://www.tensorflow.org/io/api_docs/python/tfio/audio/dbscale)\n",
        " * Expand the dimensions of each Mel power spectrogram\n",
        "\n",
        " Apply the functions to the dataset"
      ],
      "metadata": {
        "id": "UUeJTTli0E9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def spectrogram_for_map(samples, label, split):\n",
        "  spectrogram = tf.math.abs(\n",
        "      tf.signal.stft(\n",
        "        samples,\n",
        "        frame_length=480,\n",
        "        frame_step=320,\n",
        "        fft_length=256\n",
        "    )\n",
        "  )\n",
        "\n",
        "  return spectrogram, label, split\n",
        "\n",
        "def mel_spectrogram_for_map(spectrogram, label, split):\n",
        "  mel_spectrogram = tfio.audio.melscale(\n",
        "      spectrogram,\n",
        "      rate=16000,\n",
        "      mels=40,\n",
        "      fmin=0,\n",
        "      fmax=8000\n",
        "  )\n",
        "  \n",
        "  return mel_spectrogram, label, split\n",
        "\n",
        "def db_scale_for_map(mel_spectrogram, label, split):\n",
        "  mel_spectrogram = tf.maximum(1e-6, mel_spectrogram)\n",
        "  \n",
        "  dbscale_mel_spectrogram = tfio.audio.dbscale(\n",
        "      mel_spectrogram,\n",
        "      top_db=80\n",
        "  )\n",
        "  \n",
        "  return dbscale_mel_spectrogram, label, split\n",
        "\n",
        "def expand_dims_for_map(mel_spectrogram, label, split):\n",
        "  return tf.expand_dims(mel_spectrogram, axis=-1), label, split\n",
        "\n",
        "esc50_ds = esc50_ds.map(spectrogram_for_map)\n",
        "esc50_ds = esc50_ds.map(mel_spectrogram_for_map)\n",
        "esc50_ds = esc50_ds.map(db_scale_for_map)\n",
        "esc50_ds = esc50_ds.map(expand_dims_for_map)"
      ],
      "metadata": {
        "id": "p0meA8pBuNfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set random seed from reproducibility."
      ],
      "metadata": {
        "id": "6A2YLuEG1KOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.set_random_seed(42)"
      ],
      "metadata": {
        "id": "Um2ivzCPPaVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the dataset into training, validation and testing datasets, and remove the split column."
      ],
      "metadata": {
        "id": "5Ff7hckt1RB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "esc50_cached_ds = esc50_ds.cache()\n",
        "esc50_train_ds= esc50_cached_ds.filter(lambda mel_spectrogram, label, split: split == \"train\")\n",
        "esc50_val_ds = esc50_cached_ds.filter(lambda mel_spectrogram, label, split: split == \"val\")\n",
        "esc50_test_ds = esc50_cached_ds.filter(lambda mel_spectrogram, label, split: split == \"test\")\n",
        "\n",
        "# remove the split column now that it's not needed anymore\n",
        "remove_split_column = lambda embedding, label, split: (embedding, tf.cast(label, dtype=tf.float32))\n",
        "\n",
        "esc50_train_ds = esc50_train_ds.map(remove_split_column)\n",
        "esc50_val_ds = esc50_val_ds.map(remove_split_column)\n",
        "esc50_test_ds = esc50_test_ds.map(remove_split_column)\n",
        "\n",
        "esc50_train_ds = esc50_train_ds.cache().shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "esc50_val_ds = esc50_val_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "esc50_test_ds = esc50_test_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "HGSeSQsuvW_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create `Normalization` layer and adapt it on the dataset."
      ],
      "metadata": {
        "id": "4VuY6Hz41mP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for spectrogram, _, _ in esc50_cached_ds.take(1):\n",
        "    input_shape = spectrogram.shape\n",
        "    print('Input shape:', input_shape)\n",
        "  \n",
        "norm_layer = tf.keras.layers.Normalization(axis=None)\n",
        "norm_layer.adapt(esc50_cached_ds.map(lambda x, y, z: tf.reshape(x, input_shape)))"
      ],
      "metadata": {
        "id": "2utM2RDrvsng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the `tiny_conv` model using Keras."
      ],
      "metadata": {
        "id": "R96pQyaD10r1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "esc50_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Input(shape=input_shape),\n",
        "  norm_layer,\n",
        "  tf.keras.layers.DepthwiseConv2D(\n",
        "      kernel_size=(10, 8),\n",
        "      strides=(2, 2),\n",
        "      activation=\"relu\",\n",
        "      padding=\"same\",\n",
        "      depth_multiplier=8\n",
        "  ),\n",
        "  tf.keras.layers.Dropout(0.001),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(50),\n",
        "  tf.keras.layers.Activation('softmax')\n",
        "], name='esc50_model')\n",
        "\n",
        "esc50_model.summary()"
      ],
      "metadata": {
        "id": "AV9IyKG2vYD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the model and define an early stopping callback for training."
      ],
      "metadata": {
        "id": "WmYVSgnn186y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "esc50_model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\n",
        "        \"accuracy\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"loss\",\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")"
      ],
      "metadata": {
        "id": "gu0MRLsm1p1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model for up to 100 epochs."
      ],
      "metadata": {
        "id": "rwHzIZxt2Hks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = esc50_model.fit(\n",
        "    esc50_train_ds,\n",
        "    epochs=100,\n",
        "    validation_data=esc50_val_ds,\n",
        "    callbacks=[\n",
        "        early_stopping_callback\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "lLdB8yRj1q6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model on the test dataset."
      ],
      "metadata": {
        "id": "unnlev-N2qIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "esc50_model.evaluate(esc50_test_ds)"
      ],
      "metadata": {
        "id": "aXFE9ErEFRNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model."
      ],
      "metadata": {
        "id": "TeGe-FnK2uoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "esc50_model.save(\"esc50_model\")"
      ],
      "metadata": {
        "id": "e8JHq0JLPE45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a zip file of the saved model."
      ],
      "metadata": {
        "id": "0bxpJ60P2yKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.make_archive(\"esc50_model\", \"zip\", \"esc50_model\")"
      ],
      "metadata": {
        "id": "nblv7-pYfVSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FSD50k dataset and model\n",
        "\n",
        "Use the [Hugging Face dataset version of the FSD50k dataset](https://huggingface.co/datasets/Fhrozen/FSD50k). This is done to avoid downloading 25+ GB of data, `git` and `git-lfs` can be used to pull a subset of the data we need for the model.\n",
        "\n",
        "Clone the dataset from Hugging Face:"
      ],
      "metadata": {
        "id": "ofs4NURi22sU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/datasets/Fhrozen/FSD50k datasets/FSD50k"
      ],
      "metadata": {
        "id": "wpFJqScZfg2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the `dev` and `eval` dataset metadata into Pandas dataframes, assign a `split` value of \"test\" to the `eval` dataframe, and add a `fullpath` column to both dataframes with the fullpath of the `.wav` file."
      ],
      "metadata": {
        "id": "QNcSD38-3-GW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fsd50k_dev_csv_path = os.path.join(\"datasets\", \"FSD50k\", \"labels\", \"dev.csv\")\n",
        "fsd50k_eval_csv_path = os.path.join(\"datasets\", \"FSD50k\", \"labels\", \"eval.csv\")\n",
        "\n",
        "fsd50k_dev_df = pd.read_csv(fsd50k_dev_csv_path)\n",
        "fsd50k_eval_df = pd.read_csv(fsd50k_eval_csv_path)\n",
        "\n",
        "fsd50k_eval_df = fsd50k_eval_df.assign(split=\"test\")\n",
        "\n",
        "fsd50k_dev_df[\"fullpath\"] = fsd50k_dev_df[\"fname\"].map(lambda x: os.path.join(\"datasets\", \"FSD50k\", \"clips\", \"dev\", f\"{x}.wav\"))\n",
        "fsd50k_eval_df[\"fullpath\"] = fsd50k_eval_df[\"fname\"].map(lambda x: os.path.join(\"datasets\", \"FSD50k\", \"clips\", \"eval\", f\"{x}.wav\"))\n",
        "\n",
        "len(fsd50k_dev_df), len(fsd50k_eval_df)"
      ],
      "metadata": {
        "id": "0JjfjBIufkYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fsd50k_dev_df.head(-1)"
      ],
      "metadata": {
        "id": "OxM6jTmEfqHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fsd50k_eval_df.head(-1)"
      ],
      "metadata": {
        "id": "Ov9e5GxafsoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get all the dataset entries with label values that start with \"Doorbell\" and split the `dev` entries into training and validation dataframes."
      ],
      "metadata": {
        "id": "m8NMcZMt4lih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fsd50k_doorbell_train_df = fsd50k_dev_df[\n",
        "    fsd50k_dev_df.labels.str.startswith(\"Doorbell\") &\n",
        "    (fsd50k_dev_df.split == \"train\")\n",
        "]\n",
        "\n",
        "fsd50k_doorbell_val_df = fsd50k_dev_df[\n",
        "    fsd50k_dev_df.labels.str.startswith(\"Doorbell\") &\n",
        "    (fsd50k_dev_df.split == \"val\")\n",
        "]\n",
        "\n",
        "fsd50k_doorbell_test_df = fsd50k_eval_df[\n",
        "    fsd50k_eval_df.labels.str.startswith(\"Doorbell\")\n",
        "]\n",
        "\n",
        "len(fsd50k_doorbell_train_df), len(fsd50k_doorbell_val_df), len(fsd50k_doorbell_test_df)"
      ],
      "metadata": {
        "id": "AzgR1PhrftMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fsd50k_doorbell_train_df.head(-1)"
      ],
      "metadata": {
        "id": "VLt33CojrhBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select 80 training items, 10 validation items, and 10 testing values for a selection of non-doorbell label values.\n",
        "\n",
        "Then concatenate the selected dataframes into a single dataframe. "
      ],
      "metadata": {
        "id": "4wkk1It148eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LABELS = [\n",
        "    \"Doorbell\",\n",
        "    \"Music\",\n",
        "    \"Domestic_sounds_and_home_sounds\",\n",
        "    \"Human_voice\",\n",
        "    \"Hands\"\n",
        "]\n",
        "\n",
        "fsd50k_dfs = [\n",
        "    fsd50k_doorbell_train_df.assign(label=0),\n",
        "    fsd50k_doorbell_val_df.assign(label=0),\n",
        "    fsd50k_doorbell_test_df.assign(label=0)\n",
        "]\n",
        "\n",
        "for i, label in enumerate(LABELS):\n",
        "  if i == 0:\n",
        "    continue\n",
        "\n",
        "  fsd50k_label_train_df = fsd50k_dev_df[\n",
        "      ~fsd50k_dev_df.labels.str.contains(LABELS[0]) & \n",
        "      fsd50k_dev_df.labels.str.contains(label) & \n",
        "      (fsd50k_dev_df.split == \"train\")\n",
        "  ]\n",
        "  \n",
        "  fsd50k_label_train_df = fsd50k_label_train_df.sample(\n",
        "      n=min(80, len(fsd50k_label_train_df)),\n",
        "      random_state=42\n",
        "  )\n",
        "\n",
        "  fsd50k_label_eval_df = fsd50k_dev_df[\n",
        "      ~fsd50k_dev_df.labels.str.contains(LABELS[0]) & \n",
        "      fsd50k_dev_df.labels.str.contains(label) & \n",
        "      (fsd50k_dev_df.split == \"val\")\n",
        "  ]\n",
        "  \n",
        "  fsd50k_label_eval_df = fsd50k_label_eval_df.sample(\n",
        "      n=min(10, len(fsd50k_label_eval_df)),\n",
        "      random_state=42\n",
        "  )\n",
        "\n",
        "  fsd50k_label_test_df = fsd50k_eval_df[\n",
        "      ~fsd50k_eval_df.labels.str.contains(LABELS[0]) & \n",
        "      fsd50k_eval_df.labels.str.contains(label)\n",
        "  ]\n",
        "  \n",
        "  fsd50k_label_test_df = fsd50k_label_test_df.sample(\n",
        "      n=min(10, len(fsd50k_label_test_df)),\n",
        "      random_state=42\n",
        "  )\n",
        "\n",
        "  fsd50k_dfs.append(fsd50k_label_train_df.assign(label=i))\n",
        "  fsd50k_dfs.append(fsd50k_label_eval_df.assign(label=i))\n",
        "  fsd50k_dfs.append(fsd50k_label_test_df.assign(label=i))\n",
        "\n",
        "fsd50k_df = pd.concat(fsd50k_dfs)"
      ],
      "metadata": {
        "id": "D1i4qHOc72AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(fsd50k_df)"
      ],
      "metadata": {
        "id": "k7wRz5sJmkr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fsd50k_df.head(-1)"
      ],
      "metadata": {
        "id": "SJSIhaUvrJTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use `git lfs` to pull the selected `.wav` files."
      ],
      "metadata": {
        "id": "kWI-hJeI5Zoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FSD50k_DIR = os.path.join(\"datasets\", \"FSD50k\")\n",
        "\n",
        "for df in fsd50k_dfs:\n",
        "  paths = df.apply(lambda row: os.path.join(\"clips\", \"eval\" if row[\"split\"] == \"test\" else \"dev\", str(row['fname']) + \".wav\"), axis=1)\n",
        "\n",
        "  os.system(f\"git --git-dir={FSD50k_DIR}/.git --work-tree={FSD50k_DIR}/ lfs pull --include {','.join(paths)}\")"
      ],
      "metadata": {
        "id": "JZASMN-8gDtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the dataframe to a dataset."
      ],
      "metadata": {
        "id": "c8-G0KXV5g1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fsd50k_fullpaths = fsd50k_df[\"fullpath\"]\n",
        "fsd50k_labels = fsd50k_df[\"label\"]\n",
        "fsd50k_splits = fsd50k_df[\"split\"]\n",
        "\n",
        "fsd50k_ds = tf.data.Dataset.from_tensor_slices((\n",
        "    fsd50k_fullpaths,\n",
        "    fsd50k_labels,\n",
        "    fsd50k_splits\n",
        "))"
      ],
      "metadata": {
        "id": "0uKXI1P7gYRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the audio data into Mel power spectrogram format using the same pipeline functions used in the ESC-50, but truncating the wave file data to 5 seconds of audio after trim step."
      ],
      "metadata": {
        "id": "gfRlAVW756LK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fsd50k_ds = fsd50k_ds.map(lambda filepath, label, split: (load_wav(filepath), label, split))\n",
        "fsd50k_ds = fsd50k_ds.map(trim)\n",
        "fsd50k_ds = fsd50k_ds.map(lambda samples, label, split: (samples[:5 * 16000], label, split))\n",
        "fsd50k_ds = fsd50k_ds.map(frame).unbatch()\n",
        "fsd50k_ds = fsd50k_ds.map(spectrogram_for_map)\n",
        "fsd50k_ds = fsd50k_ds.map(mel_spectrogram_for_map)\n",
        "fsd50k_ds = fsd50k_ds.map(db_scale_for_map)\n",
        "fsd50k_ds = fsd50k_ds.map(expand_dims_for_map)"
      ],
      "metadata": {
        "id": "6gKmSAvig15x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fsd50k_ds = fsd50k_ds.cache()"
      ],
      "metadata": {
        "id": "FE0H6Jry96uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reset the random seed for reproducibility."
      ],
      "metadata": {
        "id": "AKA6KYGx59wm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.set_random_seed(42)"
      ],
      "metadata": {
        "id": "OeuCLs1gqZIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the dataset into training, validation, and testing sets, then remove the split column."
      ],
      "metadata": {
        "id": "eY_ABQ086CvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fsd50k_train_ds = fsd50k_ds.filter(lambda mel_spectrogram, label, split: split == \"train\")\n",
        "fsd50k_val_ds = fsd50k_ds.filter(lambda mel_spectrogram, label, split: split == \"val\")\n",
        "fsd50k_test_ds = fsd50k_ds.filter(lambda mel_spectrogram, label, split: split == \"test\")\n",
        "\n",
        "# remove the split column now that it's not needed anymore\n",
        "remove_split_column = lambda mel_spectrogram, label, fold: (mel_spectrogram, tf.cast(label, dtype=tf.float32))\n",
        "\n",
        "fsd50k_train_ds = fsd50k_train_ds.map(remove_split_column)\n",
        "fsd50k_val_ds = fsd50k_val_ds.map(remove_split_column)\n",
        "fsd50k_test_ds = fsd50k_test_ds.map(remove_split_column)\n",
        "\n",
        "fsd50k_train_ds = fsd50k_train_ds.cache().shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "fsd50k_val_ds = fsd50k_val_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "fsd50k_test_ds = fsd50k_test_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "IsGkhd4tH84T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the first 5 layers of the ESC-50 model, and set the convolutional layer as non-trainable."
      ],
      "metadata": {
        "id": "0AJTMKYN6aZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "esc50_conv_model = tf.keras.models.clone_model(\n",
        "    tf.keras.Model(\n",
        "        inputs=esc50_model.inputs,\n",
        "        outputs=[\n",
        "            esc50_model.layers[-3].output\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "\n",
        "esc50_conv_model.summary()\n",
        "\n",
        "esc50_conv_model.layers[-3].trainable = False"
      ],
      "metadata": {
        "id": "BWRi0OzjY0fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a new model with the convolutional layers and an new dense layer."
      ],
      "metadata": {
        "id": "kh0tkVXQ6vx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fsd50k_model = tf.keras.Sequential([\n",
        "  esc50_conv_model,\n",
        "  tf.keras.layers.Dense(len(LABELS), activation=\"softmax\")\n",
        "], name='fsd50k_model')\n",
        "\n",
        "fsd50k_model.summary()"
      ],
      "metadata": {
        "id": "czHQsHw_HoFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the model and create an early stopping callback."
      ],
      "metadata": {
        "id": "mEojg6KY63C9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fsd50k_model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"loss\",\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")"
      ],
      "metadata": {
        "id": "NpANq7ftIlc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model for upt to 20 epochs."
      ],
      "metadata": {
        "id": "FefNIbGS7Avd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = fsd50k_model.fit(\n",
        "    fsd50k_train_ds,\n",
        "    epochs=20,\n",
        "    validation_data=fsd50k_val_ds,\n",
        "    callbacks=[\n",
        "        early_stopping_callback\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "6JHSJWWyItYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model on the test dataset."
      ],
      "metadata": {
        "id": "URzE7cuv7E8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fsd50k_model.evaluate(fsd50k_test_ds)"
      ],
      "metadata": {
        "id": "dqVBjXU9RktD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load one of the testing files and inspect the model's prediction."
      ],
      "metadata": {
        "id": "IiQmY5Og7K8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testing_filepath = \"datasets/FSD50k/clips/eval/131642.wav\"\n",
        "testing_samples = load_wav(testing_filepath)[4000:]\n",
        "\n",
        "testing_spectrogram, _, _ = spectrogram_for_map(testing_samples[:16000], None, None)\n",
        "testing_mel_spectrogram, _, _ = mel_spectrogram_for_map(testing_spectrogram, None, None)\n",
        "testing_db_scale_mel_spectrogram, _, _ = db_scale_for_map(testing_mel_spectrogram, None, None)\n",
        "\n",
        "IPython.display.display(IPython.display.Audio(testing_samples[:16000], rate=16000))\n",
        "\n",
        "print(testing_db_scale_mel_spectrogram.shape)\n",
        "\n",
        "fsd50k_model.predict(\n",
        "    tf.expand_dims(\n",
        "        tf.expand_dims(testing_db_scale_mel_spectrogram, axis=-1)\n",
        "    , axis=0)\n",
        ")"
      ],
      "metadata": {
        "id": "TRdQd6MCOVlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model."
      ],
      "metadata": {
        "id": "WFqZitEh7Y1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fsd50k_model.save('fsd50k_model')"
      ],
      "metadata": {
        "id": "t9ZNpompoTXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a zip file for the saved model."
      ],
      "metadata": {
        "id": "0AAN8jS87asD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.make_archive(\"fsd50k_model\", \"zip\", \"fsd50k_model\")"
      ],
      "metadata": {
        "id": "fhxW4VrJqKBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the model to TensorFlow Lite format with quantization and 8-bit inputs and outputs."
      ],
      "metadata": {
        "id": "-gs7S0i07d93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(fsd50k_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "def representative_data_gen():\n",
        "  for input_value, output_value, _ in fsd50k_ds:\n",
        "    yield [input_value]\n",
        "    \n",
        "converter.representative_dataset = representative_data_gen\n",
        "converter.target_spec.supported_ops = [ tf.lite.OpsSet.TFLITE_BUILTINS_INT8 ]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "tflite_model_quant = converter.convert()\n",
        "\n",
        "with open(\"model.tflite\", \"wb\") as f:\n",
        "  f.write(tflite_model_quant)"
      ],
      "metadata": {
        "id": "IjIgjw6IT4TX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the `.tflite` model to a C array."
      ],
      "metadata": {
        "id": "iLW1sKWu7tZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "echo \"alignas(16) const unsigned char tflite_model[] = {\" > tflite_model.h\n",
        "cat model.tflite | xxd -i                                >> tflite_model.h\n",
        "echo \"};\"                                                >> tflite_model.h"
      ],
      "metadata": {
        "id": "46FwROYwVXZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create another C header file with the weight matrix for converting FFT bins to Mel scale."
      ],
      "metadata": {
        "id": "3g2LGE5h7y6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
        "    num_mel_bins=40,\n",
        "    num_spectrogram_bins=129,\n",
        "    sample_rate=16000,\n",
        "    lower_edge_hertz=0,\n",
        "    upper_edge_hertz=8000,\n",
        ").numpy().transpose()\n",
        "\n",
        "with open('mel_weight_matrix.h', 'w') as out:\n",
        "  out.write(f'const float mel_weight_matrix[{mel_weight_matrix.shape[0]}][{mel_weight_matrix.shape[1]}] = ' + '{\\n')\n",
        "  for i in range(mel_weight_matrix.shape[0]):\n",
        "    out.write('  { ' + \", \".join(mel_weight_matrix[i].astype(str)) + ' },\\n')\n",
        "\n",
        "  out.write('};\\n')\n"
      ],
      "metadata": {
        "id": "te_Si_jtXHtB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}